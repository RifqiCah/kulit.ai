{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25a30dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Deploying GPU endpoint: kulitai-gpu-prod\n",
      "----------!âœ… Endpoint siap: kulitai-gpu-prod\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.serializers import IdentitySerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# =========================================\n",
    "# KONFIGURASI\n",
    "# =========================================\n",
    "region = \"us-east-1\"\n",
    "role = \"arn:aws:iam::564415061686:role/service-role/AmazonSageMakerAdminIAMExecutionRole\"\n",
    "\n",
    "model_s3_path = (\n",
    "    \"s3://sagemaker-us-east-1-564415061686/\"\n",
    "    \"pytorch-training-2025-12-30-18-09-16-410/output/model.tar.gz\"\n",
    ")\n",
    "\n",
    "# =========================================\n",
    "# SESSION\n",
    "# =========================================\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto_session)\n",
    "\n",
    "# =========================================\n",
    "# GPU IMAGE\n",
    "# =========================================\n",
    "image_uri = image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region=region,\n",
    "    version=\"2.0\",\n",
    "    py_version=\"py310\",\n",
    "    image_scope=\"inference\",\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    ")\n",
    "\n",
    "# =========================================\n",
    "# MODEL (ANTI TIMEOUT CONFIG)\n",
    "# =========================================\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=model_s3_path,\n",
    "    role=role,\n",
    "    image_uri=image_uri,\n",
    "    entry_point=\"sagemaker_inference.py\",\n",
    "    source_dir=\"../src\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    env={\n",
    "        \"TS_DEFAULT_RESPONSE_TIMEOUT\": \"600\",\n",
    "        \"TS_MAX_RESPONSE_SIZE\": \"10000000\"\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "endpoint_name = \"kulitai-gpu-prod\"  \n",
    "\n",
    "print(\"ðŸš€ Deploying GPU endpoint:\", endpoint_name)\n",
    "\n",
    "predictor = pytorch_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=IdentitySerializer(content_type=\"application/octet-stream\"),\n",
    "    deserializer=JSONDeserializer(),\n",
    "    container_startup_health_check_timeout=600,\n",
    "    wait=True\n",
    ")\n",
    "\n",
    "print(\"âœ… Endpoint siap:\", predictor.endpoint_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08557232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kulit_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
